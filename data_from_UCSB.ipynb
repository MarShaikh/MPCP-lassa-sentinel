{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d271c109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Storage required by the CHIRPS zip files: 11.40 GB\n",
      "The above storage is taken up by compressed files, for a better estimate, we use the conversion factor of 12.735(obtained from downloading one file)\n",
      "Total true storage requirement for the CHIRPS dataset: 145.24 GB\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_table_from_link(url: str, class_: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract table data from a web page by scraping elements with a specific CSS class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The URL of the web page to scrape.\n",
    "    class_ : str\n",
    "        The CSS class name to search for within table cells.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        A list of BeautifulSoup Tag objects containing the matched table cells.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    This function assumes the target table has an id=\"list\" attribute.\n",
    "    It searches for <td> elements within that table matching the specified class.\n",
    "    \"\"\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    table_ = soup.find(id = \"list\")\n",
    "    list_ = table_.find_all(\"td\", class_=class_)\n",
    "    return list_\n",
    "\n",
    "def find_data_storage(url: str, pattern: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate total storage requirements from size data scraped from a web page.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The URL of the web page containing size information.\n",
    "    pattern : str\n",
    "        Regex pattern parameter (currently unused - function uses hardcoded pattern).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Total storage size converted to megabytes (MB).\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The function searches for table cells with class=\"size\", extracts numeric values\n",
    "    from text matching the pattern numbers with decimal points, and\n",
    "    sums them. The conversion factor 0.001024 is applied, suggesting conversion\n",
    "    from KiB to MB using binary conversion (1024 bytes per KiB, then /1000).\n",
    "    \"\"\"\n",
    "    storage_list = get_table_from_link(url, class_=\"size\")\n",
    "    \n",
    "    total_storage = 0\n",
    "    for itr in storage_list:\n",
    "        pattern = re.compile(pattern)\n",
    "        if pattern.match(itr.text):\n",
    "            storage_per_file = float(itr.text.split(\" \")[0])\n",
    "            total_storage += storage_per_file\n",
    "\n",
    "    return total_storage * 0.001024 # converting to MB\n",
    "\n",
    "\n",
    "def find_tiff_url(url: str, pattern: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract and construct URLs matching a specified pattern from a web page.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        The base URL of the web page to scrape.\n",
    "    pattern : str\n",
    "        Regex pattern to match against href attributes in links.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "        A list of complete URLs constructed by combining the base URL\n",
    "        with matching href values.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The function searches for table cells with class=\"link\", extracts href\n",
    "    attributes from anchor tags within those cells, and filters them using\n",
    "    the provided regex pattern. Complete URLs are formed by concatenating\n",
    "    the base URL with the matching href values.\n",
    "    \n",
    "    Assumes each link cell contains at least one anchor tag with an href attribute.\n",
    "    \"\"\"\n",
    "    links = get_table_from_link(url, class_ = \"link\")\n",
    "\n",
    "    all_url = []\n",
    "    for link in links:\n",
    "        temp_url = link.find_all(href = True)[0]['href']\n",
    "        pattern = re.compile(pattern)\n",
    "        if pattern.match(temp_url):\n",
    "            all_url.append(url + temp_url)\n",
    "\n",
    "    return all_url\n",
    "\n",
    "url = \"https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p05/\"\n",
    "year_urls = find_tiff_url(url, pattern = r\"\\d{4}\\/\")\n",
    "\n",
    "# get links to all TIFF files\n",
    "# for year in year_urls:\n",
    "#     data_urls = find_tiff_url(year, pattern = r\"chirps-.*\")\n",
    "#     print(data_urls)\n",
    "\n",
    "\n",
    "# get storage requirements for all tiff files\n",
    "total_storage = 0\n",
    "for year in year_urls:\n",
    "    # the storage output from this function is already in MB\n",
    "    total_storage += find_data_storage(url = year, pattern = r\"\\d+\\..+\")\n",
    "\n",
    "total_storage = total_storage * 0.001 # converting to GB\n",
    "print(f\"Total Storage required by the CHIRPS zip files: {total_storage:.2f} GB\")\n",
    "\n",
    "print(\"The above storage is taken up by compressed files, for a better estimate, we use the conversion factor of 12.735(obtained from downloading one file)\")\n",
    "print(f\"Total true storage requirement for the CHIRPS dataset: {(total_storage * 12.735):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76192bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256.98119680000013\n"
     ]
    }
   ],
   "source": [
    "url = \"https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p05/1981/\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "table = soup.find(id = \"list\")\n",
    "storage_list = table.find_all(\"td\", class_=\"size\")\n",
    "total_storage = 0\n",
    "for itr in storage_list:\n",
    "    pattern = re.compile(r\"\\d+\\..+\")\n",
    "    if pattern.match(itr.text):\n",
    "        storage_per_file = float(itr.text.split(\" \")[0])\n",
    "        total_storage += storage_per_file\n",
    "\n",
    "print(total_storage * 0.001024) # converting to MB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPCP_lassasentinel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
